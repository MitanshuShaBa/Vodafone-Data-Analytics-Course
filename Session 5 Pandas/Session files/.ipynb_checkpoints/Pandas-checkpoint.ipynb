{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy limitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# type coercion\n",
    "n1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(n1)\n",
    "n2 = np.array([[1, 2, 3], [4.0, 5.4, 6.2]])\n",
    "print(n2)\n",
    "n3 = np.array([[1, 2, 3], [4.0, 5, 'abc']])\n",
    "print(n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=[10,20,30,40,50]\n",
    "# s1 = pd.Series(data=my_data,index=['a', 'b', 'c', 'd', 'e'])\n",
    "s1 = pd.Series(data=my_data)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d={'w':10,'x':20,'y':30,'z':40}      \n",
    "#dictionary keys act as index and values with every key act as series values\n",
    "s2 = pd.Series(d)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition of two series\n",
    "# import pandas as pd\n",
    "ser1=pd.Series([1,2,3,4],['India','Srilanka', 'Bangladesh', 'Russia'])   \n",
    "\n",
    "ser2=pd.Series([1,2,5,9],['India','Srilanka', 'Bangladesh', 'Russia'])\n",
    "\n",
    "# ser2=pd.Series([1,2,5,9],['India', 'Srilanka','Bangladesh', 'Bhutan'])\n",
    "ser1+ser2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.DataFrame.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe & Select columns\n",
    "from numpy.random import randn\n",
    "import pandas as pd\n",
    "np.random.seed(10)\n",
    "df1=pd.DataFrame(randn(5,4),['A','B','C','D','E'],['W','X','Y','Z'])  \n",
    "# df1\n",
    "#generate random number for 5 rows and 4 columns\n",
    "print(df1)\n",
    "print(df1['W'])\n",
    "print(df1[['W','Z']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation: Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame.loc() will select rows by index values\n",
    "# DataFrame.iloc() will select rows by rows numbers\n",
    "print(df1)\n",
    "print(df1.loc['A']) # fetch particular row from dataset having index ‘A’\n",
    "print(df1.iloc[3]) # fetch 3rd row from dataset\n",
    "print(df1.loc[['A','C'],['X','Z']]) # fetch a subset of data from given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop('A',axis=0,inplace=False)\n",
    "# df1.drop('W',axis=1,inplace=False)\n",
    "# df1.drop('W',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "import pandas as pd\n",
    "np.random.seed(101)\n",
    "df2=pd.DataFrame(randn(5,4),['A','B','C','D','E'],['W','X','Y','Z'])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['W']>0]\n",
    "df2[df2['W']>0][['X','Y']]\n",
    "# fetch out desired frame of X & Y from dataset, for those rows where value is more than 0 in ‘W’ column\n",
    "\n",
    "# df3=df2.reset_index() #assign natural index\n",
    "# df3=df2.set_index('Z') #set ‘Z’ column as index value\n",
    "# df4 = df3.reset_index()\n",
    "# df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "d={'A':[1,2,np.NaN], 'B':[1,np.NaN,np.NaN],'C':[1,2,3]}     \n",
    "# np.NaN is the missing element in DataFrame\n",
    "df4=pd.DataFrame(d)\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df4.dropna()         #pandas would drop any row with missing value\n",
    "# df4.dropna(axis=1)   #drop column with NULL value\n",
    "df4.dropna(thresh=2) #Require <2 non-NA values to drop row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Company': [ 'CompA', 'CompA', 'CompB', 'CompB', 'CompC', 'CompC'],\n",
    "        'Person': ['Rajesh', 'Pradeep', 'Amit', 'Rakesh', 'Suresh', 'Raj'],\n",
    "        'Sales': [200, 120, 340, 124, 243, 350]}\n",
    "df6=pd.DataFrame(data)\n",
    "print(df6)\n",
    "comp=df6.groupby(\"Company\")             #grouping done using label name “Company”\n",
    "print(comp.mean())                      #mean appliead on grouped data\n",
    "# comp_std=df6.groupby(\"Company\").std()   #grouping done + standard deviation applied”\n",
    "# comp_std   \n",
    "# df6.groupby(\"Company\").sum().loc[\"CompB\"]\n",
    "# list(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Company': [ 'CompA', 'CompA', 'CompB', 'CompB', 'CompC', 'CompC'],\n",
    "        'Person': ['Rajesh', 'Pradeep', 'Amit', 'Rakesh', 'Suresh', 'Raj'],\n",
    "        'Sales': [200, 120, 340, 124, 243, 350]}\n",
    "df6=pd.DataFrame(data)\n",
    "print(df6)\n",
    "df6.groupby(\"Company\").max()\n",
    "#group dataset based on ‘company’ label and pick maximum value in each label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding unique value & number of occurrence from Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.DataFrame({'col1':[1,2,3,4],'col2':[444,555,666,444],'col3':['abc','def','ghi','xyz']})\n",
    "# col1, col2 & col3 are column labels, each column have their own values\n",
    "df7\n",
    "# df7['col2'].unique()#fetches the unique values available in column\n",
    "df7['col2'].value_counts()# count number of occurance of every value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df7['col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df7[['col2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv\n",
    "# df1 = pd.read_csv('Data/covid_19_india.csv')\n",
    "\n",
    "df2 = pd.DataFrame({'C1' : [1, 2, 3], 'C2' : [4, 5, 6], 'C3' : [7, 8, 9]})\n",
    "print(df2)\n",
    "df2.to_csv('Data/new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_excel('Data/Demo.xlsx',sheet_name='Sheet1')\n",
    "df4 = pd.read_excel('Data/Demo.xlsx',sheet_name='Sheet2')\n",
    "df5 = pd.DataFrame({'C1' : [1, 1, 1], 'C2' : [2, 2, 2], 'C3' : [3, 3, 3]})\n",
    "df5.to_excel('Data/new.xlsx', sheet_name='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance is applied on series data.\n",
    "# The Series object has a method cov() to compute covariance between series objects.\n",
    "# NA will be excluded automatically.\n",
    "# from numpy.random import randn\n",
    "# np.random.seed(101)\n",
    "# s1 = pd.Series(randn(10))\n",
    "# np.random.seed(101)\n",
    "# # s2 = pd.Series(randn(10))\n",
    "# s2 = pd.Series(randn(10)*(-1))\n",
    "s1 = pd.Series([-5,-2.5,0,2.5,5])\n",
    "s2 = pd.Series([5,-5,5,-5,5])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s1.cov(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation shows the linear relationship between any two array of values,\n",
    "# available in series. \n",
    "# There are multiple methods to compute the correlation \n",
    "        # like pearson(default), spearman and kendall.\n",
    "# from numpy.random import randn\n",
    "# np.random.seed(101)\n",
    "# s1 = pd.Series(randn(10))\n",
    "# np.random.seed(101)\n",
    "# # s2 = pd.Series(randn(10))\n",
    "# s2 = pd.Series(randn(10)*(-1))\n",
    "s1 = pd.Series([-5,-2.5,0,2.5,5])\n",
    "s2 = pd.Series([5,-5,5,-5,5])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s1.corr(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Ranking\n",
    "s = pd.Series([6,8,7,9,5], index=list('abcdef'))\n",
    "# s['a'] = s['d'] # so there's a tie\n",
    "for i in range(5):\n",
    "     print(s[i],'\\t', s.rank()[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
